temp11_celsius = resample(temp11_celsius, DEM, "bilinear")
temp10_celsius
#Attempt to create stack again
s <- stack(temp10_celsius, temp11_celsius, x$slope, x$aspect, DEM)
s
plot (s)
multi.fun <- function(x, na.rm = T) {
c(min = min(x), mean = mean(x), max = max(x), sd = sd(x))
}
extract (s, watershedPoly, fun = multi.fun)
#Good job!
Output <- extract (s, glaciersPoly, fun = multi.fun, df = TRUE)
print Output
Output
#Good job!
Output <- extract (s, glaciersPoly, fun = multi.fun, df = TRUE, na.rm=FALSE)
Output
#Good job!
Output <- extract (s, glaciersPoly, fun = multi.fun, df = TRUE, na.rm=TRUE)
Output
#Good job!
Output <- extract (s, glaciersPoly, fun = multi.fun, df = TRUE, na.rm=FALSE)
Output
#Good job!
Output <- extract (s, glaciersPoly, fun = multi.fun,  na.rm=FALSE)
Output
?extract
#Create user function to find min, mean, max, sd for the glaciers polygon
multi.fun <- function(x, na.rm = T) {
c(min = min(x, na.rm = T), mean = mean(x, na.rm = T), max = max(x, na.rm = T), sd = sd(x, na.rm =  T))
}
#Good job!
Output <- extract (s, glaciersPoly, fun = multi.fun, df = TRUE, na.rm=FALSE)
Output
plot (Output)
plot (t(Output))
t(Output)
glaciersPoly
area (glaciersPoly)
perimeter (glaciersPoly)
install.packages("OasisR")
require (OasisR)
perimeter (Output)
perimeter (glaciersPoly)
Output
t(Output)
myFile <- file.choose()
myData  <- readOGR(myFile)
myData
((3*3+2)/4+(3*3+1+2)/5)/2
# Define function to find average duration and intensity in amount/days of consecutive wet events that are equal or above 1mm.
eventIntensity<-function(x){
psum<-0 #Sum of precip per event
csum<-0 #Count of days per event
valList<-NULL
j<-1
for (i in seq (1,length(x))){
if (x[i]>=1) {
psum<-psum+x[i]
csum<-csum+1
if (i == length(x)){
if (csum<2) {}
else {valList[j] <- psum/csum}
}
} else {
if (csum<2) {}
else {
valList[j]<-psum/csum
j<-j+1
}
psum <-0
csum <-0
}
}
return (round((sum(valList)/length(valList)),2))
}
eventIntensity(x)
x
x <- c(0,0,3,3,3,2,0,0,2,0,0,3,3,1,2,3,0,0,0,0)
eventIntensity(x)
# Define function to find average duration and intensity in amount/days of consecutive wet events that are equal or above 1mm.
eventIntensity<-function(x){
psum<-0 #Sum of precip per event
csum<-0 #Count of days per event
valList<-NULL
j<-1
for (i in seq (1,length(x))){
if (x[i]>=1) {
psum<-psum+x[i]
csum<-csum+1
if (i == length(x)){
if (csum<2) {}
else {valList[j] <- psum/csum}
}
} else {
if (csum<2) {}
else {
valList[j]<-psum/csum
j<-j+1
}
psum <-0
csum <-0
}
}
return (round((sum(valList)/length(valList)),3))
}
x <- c(0,0,3,3,3,2,0,0,2,0,0,3,3,1,2,3,0,0,0,0)
((3*3+2)/4+(3*3+1+2)/5)/2
eventIntensity(x)
x <- c(0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0)
eventIntensity(x)
x <- c(1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1)
eventIntensity(x)
x <- c(0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0)
psum<-0 #Sum of precip per event
csum<-0 #Count of days per event
valList<-NULL
j<-1
length(x)
x
for (i in seq (1,length(x))){
if (x[i]>=1) {
psum<-psum+x[i]
csum<-csum+1
if (i == length(x)){
if (csum<2) {}
else {valList[j] <- psum/csum}
}
} else {
if (csum<2) {}
else {
valList[j]<-psum/csum
j<-j+1
}
psum <-0
csum <-0
}
}
valList
if (is.null(valList)){valList<-0}
valList
round((sum(valList)/length(valList)),3)
# Define function to find average duration and intensity in amount/days of consecutive wet events that are equal or above 1mm.
eventIntensity<-function(x){
psum<-0 #Sum of precip per event
csum<-0 #Count of days per event
valList<-NULL
j<-1
for (i in seq (1,length(x))){
if (x[i]>=1) {
psum<-psum+x[i]
csum<-csum+1
if (i == length(x)){
if (csum<2) {}
else {valList[j] <- psum/csum}
}
} else {
if (csum<2) {}
else {
valList[j]<-psum/csum
j<-j+1
}
psum <-0
csum <-0
}
}
if (is.null(valList)){valList<-0}
return (round((sum(valList)/length(valList)),3))
}
x <- c(0,0,3,3,3,2,0,0,2,0,0,3,3,1,2,3,0,0,0,0)
eventIntensity(x)
x <- c(0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0)
eventIntensity(x)
x <- c(1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1)
eventIntensity(x)
x <- c(1,5,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0)
eventIntensity(x)
x <- c(0,0,1,0,1,0,3,0,0,3,3,0,0,0,0,0,0,0,0,0)
eventIntensity(x)
x <- c(0,0,1,0,1,0,3,0,0,3,9,0,0,0,0,0,0,0,0,0)
eventIntensity(x)
x <- c(0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,5,30,15)
eventIntensity(x)
mean(5,30,15)
5+30
35+15
50/3
(5+30+15)/3
mean (5,30,15)
?mean
mean (c(5,30,15))
LS8_14_18 <- list.dirs(path = "D:/WorkingDir/Mapping_Projects/Thesis_pskem/R_scripts/EVI_NDVI/LS8_10th", full.names = TRUE, recursive = TRUE)
LS8_14_18 <- LS8_14_18[-1]
library(shiny); runApp('RSPrj/main.R')
library(shiny); runApp('RSPrj/main.R')
runApp('RSPrj/main.R')
x <- c(5,3,6,1,2,3,4)
x
order (x)
sort (x)
x
sort (x)
runApp('RSPrj/main.R')
runApp('RSPrj/main.R')
x <- c(1,3,5,6,2,3,5,1,6,7)
x2< - c(3,5,1,6,3,5,5,1,8,9)
x2<- c(3,5,1,6,3,5,5,1,8,9)
z <- lm(x~x2)
z
plot (z)
plot (z$residuals)
plot (z$residuals~z$fitted.values)
lines (z$residuals~z$fitted.values)
plot (z$residuals~z$fitted.values)
abline (z$residuals~z$fitted.values)
abline (z$residuals,z$fitted.values)
qqplot (z$residuals)
qqplot (z$residuals, z$fitted.values)
qqplot (z$terms)
z$coefficients
z$residuals
z$effects
z$rank
z$fitted.values
z$assign
z$qr
z$df.residual
z$model$x
z$model$x2
qqnorm (z)
qqplot (z)
z
runApp('RSPrj/main.R')
runApp('RSPrj/main.R')
runApp('RSPrj/main.R')
runApp('RSPrj/main.R')
runApp('RSPrj/main.R')
runApp('RSPrj/main.R')
Sys.which("git")
git
sys.where git
Sys.which("git")
x <- read.csv ("example.csv")
summary(lm (x$Ni ~ x$Toc))
summary(lm (x$Ni ~ x$Size))
summary(lm (x$Ni ~ x$Size+x$Toc:x$Size))
plot (step(lm(x$Ni ~x$Size*x$Toc)))
fit <- lm(x$Ni ~x$Size*x$Toc)
fit2 <- (lm (x$Ni ~ x$Size+x$Toc:x$Size))
z<-x$Ni-((x$Size-t_s)*-1.56258+((x$Toc*x$Size)-(t_t*t_s))*0.21)
t_s<- 10
t_t <- 4
j<-x$Toc*x$Size
par(mfrow=c(2,2))
plot (x$Ni~x$Size)
plot (x$Ni~j)
plot (z~x$Size)
plot (z~j)
setwd("~/RSPrj")
x <- read.csv ("example.csv")
summary(lm (x$Ni ~ x$Toc))
summary(lm (x$Ni ~ x$Size))
summary(lm (x$Ni ~ x$Size+x$Toc:x$Size))
plot (step(lm(x$Ni ~x$Size*x$Toc)))
fit <- lm(x$Ni ~x$Size*x$Toc)
fit2 <- (lm (x$Ni ~ x$Size+x$Toc:x$Size))
z<-x$Ni-((x$Size-t_s)*-1.56258+((x$Toc*x$Size)-(t_t*t_s))*0.21)
t_s<- 10
t_t <- 4
j<-x$Toc*x$Size
par(mfrow=c(2,2))
plot (x$Ni~x$Size)
plot (x$Ni~j)
plot (z~x$Size)
plot (z~j)
setwd("~/")
rm(list = ls())
rm(list = ls())
rm(list = ls())
# Load the required R libraries
install.packages("RColorBrewer")
install.packages("tm")
install.packages("wordcloud")
install.packages('base64enc')
install.packages('ROAuth')
install.packages('plyr')
install.packages('stringr')
install.packages('twitteR')
library(RColorBrewer)
library(wordcloud)
library(tm)
library(twitteR)
library(ROAuth)
library(plyr)
library(stringr)
library(base64enc)
download.file(url="http://curl.haxx.se/ca/cacert.pem",destfile="cacert.pem")
consumerKey <- "889840922825019393-rDamD3WqBEwv9SNovddqYeZat5sXHlh"
consumerSecret <- "adifAyNKgcT5lY5H1KsN2DkDzXfcvtnQtTARvtyNLYArU"
rm(list = ls())
# Load the required R libraries
install.packages("RColorBrewer")
install.packages("tm")
install.packages("wordcloud")
install.packages('base64enc')
install.packages('ROAuth')
install.packages('plyr')
install.packages('stringr')
install.packages('twitteR')
library(RColorBrewer)
library(wordcloud)
library(tm)
library(twitteR)
library(ROAuth)
library(plyr)
library(stringr)
library(base64enc)
download.file(url="http://curl.haxx.se/ca/cacert.pem",destfile="cacert.pem")
# Set constant requestURL
requestURL <- "https://api.twitter.com/oauth/request_token"
# Set constant accessURL
accessURL <- "https://api.twitter.com/oauth/access_token"
# Set constant authURL
authURL <- "https://api.twitter.com/oauth/authorize"
setup_twitter_oauth(consumerKey,
consumerSecret,
accessToken,
accessTokenSecret)
consumerKey <- "mQlBizLfUy4kAhX7KpL4tHLIR"
consumerSecret <- "Panl7AQPfAKGp36S6priHnZnxSXXI07z33vL7X2SJV2V7cXYfZ"
accessToken <- "889840922825019393-rDamD3WqBEwv9SNovddqYeZat5sXHlh"
accessTokenSecret <- "adifAyNKgcT5lY5H1KsN2DkDzXfcvtnQtTARvtyNLYArU"
install.packages("RColorBrewer")
install.packages("tm")
install.packages("base64enc")
install.packages("ROAuth")
install.packages("plyr")
install.packages("wordcloud")
install.packages("stringr")
install.packages("twitteR")
install.packages("base64enc")
install.packages("plyr")
install.packages("stringr")
install.packages("ROAuth")
install.packages("wordcloud")
install.packages("twitteR")
install.packages("stringr")
install.packages("twitteR")
install.packages("ROAuth")
install.packages("wordcloud")
install.packages("ROAuth")
install.packages("wordcloud")
Objectname <- searchTwitter(searchString, n=no.of tweets, lang=NULL)
Objectname <- searchTwitter(searchString, n=1000, lang=NULL)
install.packages(twitterR)
install.packages("twitteR")
library(twitteR)
tweets_g <- searchTwitter("#google", n=1000,lang = "en")
tweets_a <- searchTwitter("#amazon", n=1000,lang = "en")
tweets_f <- searchTwitter("#facebook", n=1000,lang = "en")
tweets_tech <- searchTwitter("#technology", n=1000,lang = "en")
setup_twitter_oauth(consumerKey,
consumerSecret,
accessToken,
accessTokenSecret)
tweets_g <- searchTwitter("#google", n=1000,lang = "en")
tweets_a <- searchTwitter("#amazon", n=1000,lang = "en")
tweets_f <- searchTwitter("#facebook", n=1000,lang = "en")
tweets_tech <- searchTwitter("#technology", n=1000,lang = "en")
amazon_tweets <- twListToDF(tweets_a)
google_tweets <- twListToDF(tweets_g)
facebook_tweets <- twListToDF(tweets_f)
tech_tweets <- twListToDF(tweets_tech)
View(tech_tweets)
# Replace blank space (“rt”)
google_text <- gsub("rt", "", google_text)
#convert all text to lower case
google_text<- tolower(google_text)
google_text<- google_tweets$text
amazon_text<- amazon_tweets$text
facebook_text<- facebook_tweets$text
tech_text<- tech_tweets$text
#convert all text to lower case
google_text<- tolower(google_text)
amazon_text<- tolower(amazon_text)
facebook_text<- tolower(facebook_text)
tech_text<- tolower(tech_text)
# Replace blank space (“rt”)
google_text <- gsub("rt", "", google_text)
amazon_text <- gsub("rt", "", amazon_text)
facebook_text <- gsub("rt", "", facebook_text)
tech_text <- gsub("rt", "", tech_text)
# Replace @UserName
google_text <- gsub("@\\w+", "", google_text)
amazon_text <- gsub("@\\w+", "", amazon_text)
facebook_text <- gsub("@\\w+", "", facebook_text)
tech_text <- gsub("@\\w+", "", tech_text)
# Remove punctuation
google_text <- gsub("[[:punct:]]", "", google_text)
amazon_text <- gsub("[[:punct:]]", "", amazon_text)
facebook_text <- gsub("[[:punct:]]", "", facebook_text)
tech_text <- gsub("[[:punct:]]", "", tech_text)
# Remove links
google_text <- gsub("http\\w+", "", google_text)
amazon_text <- gsub("http\\w+", "", amazon_text)
facebook_text <- gsub("http\\w+", "", facebook_text)
tech_text <- gsub("http\\w+", "", tech_text)
# Remove tabs
google_text <- gsub("[ |\t]{2,}", "", google_text)
amazon_text <- gsub("[ |\t]{2,}", "", amazon_text)
facebook_text <- gsub("[ |\t]{2,}", "", facebook_text)
tech_text <- gsub("[ |\t]{2,}", "", tech_text)
# Remove blank spaces at the beginning
google_text <- gsub("^ ", "", google_text)
amazon_text <- gsub("^ ", "", amazon_text)
facebook_text <- gsub("^ ", "", facebook_text)
tech_text <- gsub("^ ", "", tech_text)
# Remove blank spaces at the end
google_text <- gsub(" $", "", google_text)
amazon_text <- gsub(" $", "", amazon_text)
facebook_text <- gsub(" $", "", facebook_text)
tech_text <- gsub(" $", "", tech_text)
#clean up by removing stop words
google_tweets.text.corpus <- tm_map(google_tweets.text.corpus, function(x)removeWords(x,stopwords()))
#clean up by removing stop words
google_tweets.text.corpus <- tm_map(google_tweets.text.corpus, function(x)removeWords(x,stopwords()))
View(amazon_tweets)
#clean up by removing stop words
google_tweets.text.corpus <- tm_map(google_tweets$text, function(x)removeWords(x,stopwords()))
#clean up by removing stop words
google_tweets.text.corpus <- tm_map(google_text, function(x)removeWords(x,stopwords()))
#clean up by removing stop words
google_tweets.text.corpus <- tm_map(google_tweets.text.corpus, function(x)removeWords(x,stopwords()))
google_tweets
#clean up by removing stop words
google_tweets.text.corpus <- tm_map(google_tweets, function(x)removeWords(x,stopwords()))
library("NLP")
library("syuzhet")
library("topicmodels")
install.packages("topicmodels")
install.packages("stringi")
install.packages("SnowballC")
install.packages("syuzhet")
install.packages("NLP")
# install.packages('twitteR')
library(RColorBrewer)
library(wordcloud)
library(tm)
library(twitteR)
library(ROAuth)
library(plyr)
library(stringr)
library(base64enc)
library("NLP")
library("syuzhet")
library("SnowballC")
library("stringi")
library("topicmodels")
install.packages("stringi")
# install.packages('twitteR')
library(RColorBrewer)
library(wordcloud)
library(tm)
library(twitteR)
library(ROAuth)
library(plyr)
library(stringr)
library(base64enc)
library("NLP")
library("syuzhet")
library("SnowballC")
library("stringi")
library("topicmodels")
library(stringi)
#clean up by removing stop words
google_tweets.text.corpus <- tm_map(google_tweets.text.corpus, function(x)removeWords(x,stopwords()))
removeWords()
stopwords()
?tm_map
library("stringi", lib.loc="~/R/win-library/3.3")
library(shiny); runApp('RSPrj/main.R')
styler:::style_active_file()
runApp('ShinyTwit/ShinyTwit.R')
runApp('ShinyTwit/ShinyTwit.R')
runApp('ShinyTwit/ShinyTwit.R')
runApp('ShinyTwit/ShinyTwit.R')
runApp('ShinyTwit/ShinyTwit.R')
runApp('ShinyTwit/ShinyTwit.R')
runApp('ShinyTwit/ShinyTwit.R')
runApp('ShinyTwit/ShinyTwit.R')
runApp('ShinyTwit/ShinyTwit.R')
htmlOutput()
?htmlOutput
runApp('ShinyTwit/ShinyTwit.R')
runApp('ShinyTwit/ShinyTwit.R')
runApp('ShinyTwit/ShinyTwit.R')
runApp('ShinyTwit/ShinyTwit.R')
runApp('ShinyTwit/ShinyTwit.R')
runApp('ShinyTwit/ShinyTwit.R')
runApp('ShinyTwit/ShinyTwit.R')
runApp('ShinyTwit/ShinyTwit.R')
runApp('ShinyTwit/ShinyTwit.R')
styler:::style_active_file()
runApp('ShinyTwit/ShinyTwit.R')
styler:::style_active_file()
taskscheduleR:::taskschedulerAddin()
taskscheduleR:::taskschedulerAddin()
taskscheduleR:::taskschedulerAddin()
setwd("~/ShinyTwit")
taskscheduleR:::taskschedulerAddin()
setwd("~/ShinyTwit")
900/60
